{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5c4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv1D\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "from tensorflow.python.keras.layers import  CuDNNGRU,  CuDNNLSTM\n",
    "from tensorflow.python.keras.layers import LSTM,GRU\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def all_models(shape,dropout):\n",
    "    def get_cudnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"CuDNNGRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNGRU(64,input_shape=(shape),return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNGRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNGRU(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNGRU3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNGRU(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNGRU4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNGRU(64,return_sequences=False))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "        \n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "            \n",
    "        return model\n",
    "       \n",
    "        \n",
    "    def get_cudnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"CuDNNLSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,input_shape=(shape),return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNLSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=False))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "    def get_cudnn3lstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"CuDNNLSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,input_shape=(shape),return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNLSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNLSTM5\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM6\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=False))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def get_cudnncnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"Conv1D1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Conv1D(128, input_shape=(train_X.shape[1:]), kernel_size=3, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.5))\n",
    "        with tf.variable_scope(\"Conv1D2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Conv1D(128,kernel_size=3, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.5))\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNLSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=False))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    " \n",
    "    def get_fastrnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"LSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,input_shape=(shape),return_sequences=True, celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"LSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=True,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"LSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=True,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"LSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=False,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_fastgrnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"LSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,input_shape=(shape),return_sequences=True, celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"LSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=True,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"LSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=True,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"LSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=False,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_optfastgrnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"LSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(128,input_shape=(shape),return_sequences=True, celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"LSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=False,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(32, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "\n",
    "        return model\n",
    "        \n",
    "    def get_optfastrnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"LSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(128,input_shape=(shape),return_sequences=True, celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"LSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=False,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(32, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    " \n",
    "    def get_fastrnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"GRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,input_shape=(shape),return_sequences=True, celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"GRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=True,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"GRU3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=True,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"GRU4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=False,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_fastgrnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"GRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,input_shape=(shape),return_sequences=True, celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"GRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=True,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"GRU3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=True,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"GRU4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=False,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_optfastgrnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"GRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(128,input_shape=(shape),return_sequences=True, celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"GRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=False,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(32, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "\n",
    "        return model\n",
    "        \n",
    "    def get_optfastrnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"GRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(128,input_shape=(shape),return_sequences=True, celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"GRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=False,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(32, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf501fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make necessary code changes as per the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-93c5f35d0f3a>:37: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  myarray = np.fromstring(line, dtype=float, sep=',')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 0 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-93c5f35d0f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtest_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmyarray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mmyarray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyarray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtest_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmyarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5390\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5391\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5392\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 0 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv1D\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sys\n",
    " \n",
    " \n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "print(\"Please make necessary code changes as per the dataset\")\n",
    "# change shape if selected feature dataset is used\n",
    "test_X=np.empty((0,53),float)\n",
    "test_y=np.empty((0,1),int)\n",
    "\n",
    "\n",
    "# choose model from all_models\n",
    "model=all_models([100,53],0.7) #(shape,dropout) in accordance to dataset\n",
    "\n",
    "i=0\n",
    "with open(\"/Users/chad/Desktop/340WParentPaper-master/dataset/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\", 'r') as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        myarray = np.fromstring(line, dtype=float, sep=',')\n",
    "        if myarray.size!=0:\n",
    "            test_y=np.array([myarray[-1]])\n",
    "            myarray=myarray[:-1]\n",
    "            test_X=np.append(test_X,[myarray],axis=0)\n",
    "            i+=1\n",
    "            if(i==100):\n",
    "                y=model.predict(np.reshape(test_X,[1,100,53]))\n",
    "                print(y,test_y)\n",
    "                test_X=np.delete(test_X,0,axis=0)\n",
    "                test_y=np.empty((0,1),int)\n",
    "                i=99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630b86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "248727b8d46c445d6917531defa5c5f65af0d3d96acf95264c2fbcc38e7ee33b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
