{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa5c4d33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yt/dnk5jld17p3_gqrq2wj5106m0000gn/T/ipykernel_1036/3298790684.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv1D\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "from tensorflow.compat.v1.keras.layers import  CuDNNGRU,  CuDNNLSTM\n",
    "from tensorflow.python.keras.layers import LSTM,GRU\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def all_models(shape,dropout):\n",
    "    def get_cudnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"CuDNNGRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNGRU(64,input_shape=(shape),return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNGRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNGRU(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNGRU3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNGRU(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNGRU4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNGRU(64,return_sequences=False))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "        \n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "            \n",
    "        return model\n",
    "       \n",
    "        \n",
    "    def get_cudnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"CuDNNLSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,input_shape=(shape),return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNLSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=False))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "    def get_cudnn3lstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"CuDNNLSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,input_shape=(shape),return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNLSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNLSTM5\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM6\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=False))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def get_cudnncnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"Conv1D1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Conv1D(128, input_shape=(train_X.shape[1:]), kernel_size=3, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.5))\n",
    "        with tf.variable_scope(\"Conv1D2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Conv1D(128,kernel_size=3, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.5))\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"CuDNNLSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=True))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"CuDNNLSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(CuDNNLSTM(64,return_sequences=False))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    " \n",
    "    def get_fastrnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"LSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,input_shape=(shape),return_sequences=True, celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"LSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=True,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"LSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=True,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"LSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=False,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_fastgrnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"LSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,input_shape=(shape),return_sequences=True, celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"LSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=True,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"LSTM3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=True,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"LSTM4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=False,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_optfastgrnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"LSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(128,input_shape=(shape),return_sequences=True, celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"LSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=False,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(32, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "\n",
    "        return model\n",
    "        \n",
    "    def get_optfastrnnlstm(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"LSTM1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(128,input_shape=(shape),return_sequences=True, celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"LSTM2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(LSTM(64,return_sequences=False,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(32, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    " \n",
    "    def get_fastrnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"GRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,input_shape=(shape),return_sequences=True, celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"GRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=True,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"GRU3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=True,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"GRU4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=False,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_fastgrnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"GRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,input_shape=(shape),return_sequences=True, celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"GRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=True,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"GRU3\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=True,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "        with tf.variable_scope(\"GRU4\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=False,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_optfastgrnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"GRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(128,input_shape=(shape),return_sequences=True, celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"GRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=False,celltype=\"FastGRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(32, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "\n",
    "        return model\n",
    "        \n",
    "    def get_optfastrnngru(shape,dropout):\n",
    "        model = Sequential()\n",
    "        with tf.variable_scope(\"GRU1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(128,input_shape=(shape),return_sequences=True, celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "            \n",
    "        with tf.variable_scope(\"GRU2\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(GRU(64,return_sequences=False,celltype=\"FastRNNCell\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\t\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"DENSE1\" ,reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(32, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        with tf.variable_scope(\"DENSE2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            opt = tf.keras.optimizers.Adam(lr=1e-2, decay=1e-3)\n",
    "            model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf501fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make necessary code changes as per the dataset\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'GRU'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-63721730612b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# choose model from all_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m53\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(shape,dropout) in accordance to dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'GRU'"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Flatten, Conv1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sys\n",
    " \n",
    " \n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "print(\"Please make necessary code changes as per the dataset\")\n",
    "# change shape if selected feature dataset is used\n",
    "test_X=np.empty((0,53),float)\n",
    "test_y=np.empty((0,1),int)\n",
    "\n",
    "\n",
    "# choose model from all_models\n",
    "model=all_models.GRU([100,53],0.7) #(shape,dropout) in accordance to dataset\n",
    "\n",
    "i=0\n",
    "with open(sys.argv[1]) as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        myarray = np.fromstring(line, dtype=float, sep=',')\n",
    "        if myarray.size!=0:\n",
    "            test_y=np.array([myarray[-1]])\n",
    "            myarray=myarray[:-1]\n",
    "            test_X=np.append(test_X,[myarray],axis=0)\n",
    "            i+=1\n",
    "            if(i==100):\n",
    "                y=model.predict(np.reshape(test_X,[1,100,53]))\n",
    "                print(y,test_y)\n",
    "                test_X=np.delete(test_X,0,axis=0)\n",
    "                test_y=np.empty((0,1),int)\n",
    "                i=99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630b86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
